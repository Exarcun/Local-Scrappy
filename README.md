<div align="center">

# ğŸ¦ Local-Scrappy

**A powerful web scraper for Swiss business data**

[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![Selenium](https://img.shields.io/badge/Selenium-4.38+-43B02A?style=for-the-badge&logo=selenium&logoColor=white)](https://selenium.dev)
[![Firefox](https://img.shields.io/badge/Firefox-Browser-FF7139?style=for-the-badge&logo=firefox&logoColor=white)](https://mozilla.org/firefox)
[![SQLite](https://img.shields.io/badge/SQLite-Database-003B57?style=for-the-badge&logo=sqlite&logoColor=white)](https://sqlite.org)

Extract business data from [local.ch](https://local.ch), the Swiss business directory.

---

</div>

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ–¥ï¸ **Interactive Console** | Guided setup with prompts for all options |
| âš¡ **Parallel Workers** | Scale from 1 to 20 concurrent workers |
| ğŸ”„ **Proxy Rotation** | Hot/cold pool with automatic recovery |
| ğŸ’¾ **SQLite Storage** | Persistent database per region |
| ğŸ“Š **Excel Export** | Business classification & filtering |

---

## ğŸ“¦ Requirements

### System
- ğŸ Python 3.10+
- ğŸ¦Š Firefox (regular or Developer Edition)
- ğŸ”§ geckodriver

### Dependencies

```bash
pip install selenium pandas openpyxl
```

---

## ğŸš€ Quick Start

### 1. Clone & Install

```bash
git clone https://github.com/Exarcun/Local-Scrappy.git
cd Local-Scrappy
pip install selenium pandas openpyxl
```

### 2. Configure

Edit `src/config.py` with your paths:

```python
FIREFOX_PATH = r"C:\Program Files\Mozilla Firefox\firefox.exe"
GECKODRIVER_PATH = r"C:\path\to\geckodriver.exe"
```

### 3. Run

```bash
cd src
python main.py
```

---

## ğŸ® Usage

The interactive console guides you through:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¦ Local-Scrappy v1.0                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1ï¸âƒ£  Enter local.ch search URL                          â”‚
â”‚  2ï¸âƒ£  Configure pages, workers, delay                    â”‚
â”‚  3ï¸âƒ£  Watch scraping progress                            â”‚
â”‚  4ï¸âƒ£  Export to Excel                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Configuration

| Option | Default | Description |
|:------:|:-------:|-------------|
| ğŸ“„ Pages | `150` | Search result pages to scrape |
| ğŸ‘· Workers | `1` | Parallel workers (1-20) |
| âŒ Max Errors | `3` | Errors before proxy swap |
| â±ï¸ Delay | `0.3s` | Delay between requests |

---

## ğŸ“ Project Structure

```
Local-Scrappy/
â”œâ”€â”€ ğŸ“‚ src/                     # Source code
â”‚   â”œâ”€â”€ main.py                 # Entry point
â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â”œâ”€â”€ db.py                   # Database operations
â”‚   â”œâ”€â”€ scraper.py              # Scraping functions
â”‚   â”œâ”€â”€ proxy.py                # Proxy management
â”‚   â””â”€â”€ worker.py               # Parallel execution
â”œâ”€â”€ ğŸ“‚ scripts/                 # Export scripts
â”‚   â”œâ”€â”€ export_all.py
â”‚   â”œâ”€â”€ export_business.py
â”‚   â””â”€â”€ export_uncategorized.py
â”œâ”€â”€ ğŸ“‚ data/                    # SQLite databases
â”œâ”€â”€ ğŸ“‚ proxies/                 # Proxy lists
â””â”€â”€ ğŸ“‚ output/                  # Excel exports
```

---

## ğŸ“Š Data Fields

| Field | Description |
|-------|-------------|
| `name` | Business or person name |
| `type` | Business category |
| `address` | Street address with postal code |
| `phone` | Phone number |
| `email` | Email address |
| `website` | Website URL |
| `source_url` | Original local.ch page |

---

## ğŸ”€ Proxy Support (Optional)

Add IP-authenticated proxies to `proxies/proxylist.txt`:

```
http://proxy1.example.com:8080
http://proxy2.example.com:8080
```

The system uses **hot/cold pool rotation**:
- â„ï¸ **Cold proxies**: Available for use
- ğŸ”¥ **Hot proxies**: Failed, cooling down (5 min)
- ğŸ”„ Auto-swap after 3 consecutive errors

---

## ğŸ“¤ Export Scripts

Run through the console menu or manually:

```bash
# Export businesses only
python scripts/export_business.py data/yourdb.db

# Export all records
python scripts/export_all.py data/yourdb.db

# Export uncategorized
python scripts/export_uncategorized.py data/yourdb.db
```

### Business Classification

Records are classified as **businesses** if they have:
- âœ… A type/category field
- âœ… A website
- âœ… Business suffix (SA, AG, GmbH, Sagl, Srl, etc.)

---

## ğŸ“„ License

MIT

---

<div align="center">

**Made with ğŸ¦ by [Exarcun](https://github.com/Exarcun)**

</div>
